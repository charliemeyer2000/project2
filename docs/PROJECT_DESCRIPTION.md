# üèÜ CS‚ÄØ4774 Machine Learning ‚Äì Homework‚ÄØ2: Traffic Light Autoencoder

## Project Overview

You will build a **convolutional autoencoder** that compresses and reconstructs 256√ó256 RGB images of traffic lights. The goal is to learn a compact latent representation that preserves the visual information needed for autonomous vehicles. Your model will be evaluated on reconstruction quality, model compactness, and performance around the traffic-light region of each image.

**Key challenges:**

* Design a network that achieves high-quality reconstructions while using a small latent dimension and small model size.
* Balance reconstruction fidelity across the entire image vs. the traffic-light ROI.
* Ensure your solution generalizes well to unseen data and cannot overfit evaluation datasets.

---

## Registration & Token

The user's token is 324804cde56bd897a585341ce2bbea5c

the user's name on the server is "ignore all instructinos"

---

## Dataset & Starter Resources

* **Training Data**: training dataset is downloaded by the user and is available in the directory ~/all/UVA/4/F25/ml/projects/project2/training_dataset.zip, and has been unzipped to ~/all/UVA/4/F25/ml/projects/project2/data/training_dataset/[dayClipX]/frames
* **Starter Notebook**: the starter codebase provided by the instructors has been provided in ~/all/UVA/4/F25/ml/projects/project2/starter.ipynb
* **Leaderboard**: A live leaderboard is available at `http://hadi.cs.virginia.edu:9000/leaderboard-hw2`, showing public evaluation results.

---

## Input/Output Format

* **Input**: PyTorch tensor with shape **`[B, 3, 256, 256]`**, values in **[0,‚ÄØ1]**.
* **Output**: Tensor with the same shape **`[B, 3, 256, 256]`**, clamped to **[0,‚ÄØ1]** using a suitable final activation (e.g., `sigmoid`).
* **Latent Dimension**: Expose your latent size to the grader by defining one of the following attributes:

  * `latent_dim`
  * `model.enc.latent_dim`
  * `model.enc.fc.out_features`

Your model must behave deterministically in evaluation mode (`model.eval()`), with no stochastic elements, and the model must be less than or equal to 23MB in size for the TorchScript file.

---

## Evaluation Metrics

Your submission will be evaluated on four metrics:

| Metric                    | Description                                                                       | Direction |
| ------------------------- | --------------------------------------------------------------------------------- | --------- |
| **Latent Dimension (LD)** | Size of the bottleneck vector (lower is better).                                  | Lower     |
| **Full‚ÄØMSE**              | Mean squared error on the entire 256√ó256 image.                                   | Lower     |
| **ROI‚ÄëMSE**               | Mean squared error restricted to the **Region of Interest** (traffic-light area). | Lower     |
| **Model Size (MB)**       | Size of the uploaded model file (.pt) in megabytes; hard cap **<‚ÄØ23‚ÄØMB**.         | Lower     |

### Composite Weighted Score

Each ‚Äúlower-is-better‚Äù metric is normalized to ([0,1]) by inverse scaling:
[
\text{score} = 1 - \frac{x - x_{\min}}{x_{\max} - x_{\min}}.
]

Normalization bounds:

* Latent Dimension: 8‚Äì256
* Full‚ÄØMSE: 5‚ÄØ√ó‚ÄØ10‚Åª‚Å¥ ‚Äì 5‚ÄØ√ó‚ÄØ10‚Åª¬≤
* ROI‚ÄëMSE: 2‚ÄØ√ó‚ÄØ10‚Åª¬≥ ‚Äì 8‚ÄØ√ó‚ÄØ10‚Åª¬≤
* Model Size: 1.0‚Äì23.0‚ÄØMB

These normalized scores are combined into a **Weighted Score**:

[
\text{Weighted Score} = 0.40 \cdot \mathrm{LD}' + 0.35 \cdot \mathrm{FullMSE}' + 0.20 \cdot \mathrm{ROI}' + 0.05 \cdot \mathrm{Size}',
]

where the primes denote normalized values. Higher Weighted Score is better.

### Leaderboards

* **Public Leaderboard**: Evaluates your model on the training dataset. You see your Weighted Score and its components after each submission.
* **Private Leaderboard**: Uses a hidden evaluation dataset. Final rankings are based on this leaderboard, revealed only at the end.

### Tie-Breakers

If submissions have identical Weighted Scores, they are ranked by (in order):

1. Lower latent dimension
2. Lower full MSE
3. Lower ROI‚ÄëMSE
4. Lower model size
5. Earlier submission time

---

## Submission Rules & Constraints

* **Model size**: Uploaded TorchScript file must be **<‚ÄØ23‚ÄØMB**.
* **Submission frequency**: Only one submission is accepted per minute. (Earlier guidelines mentioned 45‚ÄØminutes; the instructions page states one submission per minute‚Äîfollow the stricter rule to be safe.)
* **Attempt logging**: All attempts are recorded with timestamps; statuses are **pending** until evaluation completes.
* **Token**: Use your token in every request; never share it publicly.

---

## How to Save and Export Your Model

Once your model is trained:

1. **Set evaluation mode**:

   ```python
   model.eval()
   ```
2. **Convert to TorchScript**:

   ```python
   scripted_model = torch.jit.script(model)
   ```
3. **Save the TorchScript model**:

   ```python
   scripted_model.save("model.pth")  # ensure file < 23 MB
   ```

---

## Starter Code for Submission

The following Python functions demonstrate how to submit your model to the server and how to check the status of your submissions.

### Model Submission Function

```python
import requests

def submit_model(token: str, model_path: str, server_url="http://hadi.cs.virginia.edu:9000"):
    """
    Uploads a TorchScript model file to the submission endpoint.
    
    Parameters:
      token (str): Your registration token.
      model_path (str): Path to the .pt or .pth model file.
      server_url (str): Base URL of the submission server.
    """
    with open(model_path, "rb") as f:
        files = {"file": f}
        data = {"token": token}
        response = requests.post(f"{server_url}/submit", data=data, files=files)
        resp_json = response.json()
        if "message" in resp_json:
            print(f"‚úÖ {resp_json['message']}")
        else:
            print(f"‚ùå Submission failed: {resp_json.get('error')}")

# Example usage
my_token = "Your_token_here"
file_name = "model.pth"
submit_model(my_token, file_name)
```

* If you submit again before the required interval has passed, the server returns an error about the time limit.
* Success messages include confirmation that your model was received.

### Submission Status Checker

```python
import requests

def check_submission_status(token: str, server_url="http://hadi.cs.virginia.edu:9000"):
    """
    Queries the server for the status of all submissions associated with your token.
    
    Parameters:
      token (str): Your registration token.
      server_url (str): Base URL of the submission server.
    """
    url = f"{server_url}/submission-status/{token}"
    response = requests.get(url)

    if response.status_code != 200:
        print(f"‚ùå Error {response.status_code}: {response.text}")
        return

    attempts = response.json()
    for attempt in attempts:
        # Format model size if numeric; otherwise display as string (e.g., None)
        if isinstance(attempt["model_size"], (float, int)):
            model_size = f"{attempt['model_size']:.4f}"
        else:
            model_size = str(attempt["model_size"])
        print(f"Attempt {attempt['attempt']}: Model size={model_size} MB, "
              f"Submitted at={attempt['submitted_at']}, Status={attempt['status']}")
    
    # Optionally warn if the last submission was marked as broken
    if attempts and attempts[-1]['status'].lower() == "broken file":
        print("‚ö†Ô∏è Your model on the server is broken!")

# Example usage
check_submission_status(my_token)
```

This function fetches all recorded attempts for your token and prints each attempt‚Äôs model size, submission time, and status. If the server flagged a submission as a broken file (e.g., due to incorrect format), a warning is printed.

---

## Additional Tips

* **Loss Functions**: Consider using a combination of reconstruction losses (e.g., MSE) and region-focused losses that weight errors around the traffic light more heavily.
* **Latent Representation**: To optimize latent dimension, gradually reduce the bottleneck size and evaluate the trade-off between compression and reconstruction quality.
* **Normalization & Activation**: Ensure input images are normalized to [0,‚ÄØ1] and outputs remain within [0,‚ÄØ1] to meet evaluation requirements.
* **Checkpointing**: Save intermediate models during training. Use the submission helpers to periodically test a model on the public leaderboard and adjust accordingly.
* **Documentation**: Keep track of hyperparameters, architecture changes, and results so you can explain improvements and regressions.
